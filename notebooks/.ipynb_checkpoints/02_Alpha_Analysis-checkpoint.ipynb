{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha Metrics Analysis\n",
    "## Understanding Finishing Alpha and Playmaking Alpha\n",
    "### Dual-Source: FBref Stats + Understat xG\n",
    "\n",
    "This notebook explains the core \"Alpha\" metrics - borrowed from quantitative finance - applied to football analytics.\n",
    "\n",
    "**Alpha = Actual Performance \u2212 Expected Performance**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from adjustText import adjust_text\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from analysis import get_data\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "df = get_data()\n",
    "\n",
    "# Position helper\n",
    "def get_pos(p):\n",
    "    if pd.isna(p): return 'Unknown'\n",
    "    p = p.upper()\n",
    "    if 'GK' in p: return 'GK'\n",
    "    elif 'DF' in p: return 'DF'\n",
    "    elif 'MF' in p: return 'MF'\n",
    "    elif 'FW' in p: return 'FW'\n",
    "    return 'Unknown'\n",
    "\n",
    "df['main_pos'] = df['pos'].apply(get_pos)\n",
    "print(f\"Loaded {len(df)} players | xG coverage: {df['xg'].notna().sum()}/{len(df)}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Alpha?\n",
    "\n",
    "In finance, **Alpha (\u03b1)** represents the excess return of an investment relative to a benchmark index.\n",
    "\n",
    "In football analytics, we apply the same concept:\n",
    "\n",
    "| Metric | Formula | Interpretation |\n",
    "|--------|---------|----------------|\n",
    "| **Finishing Alpha** | Goals \u2212 xG | Overperforming (+) or underperforming (\u2212) expected goals |\n",
    "| **Playmaking Alpha** | Assists \u2212 xAG | Overperforming (+) or underperforming (\u2212) expected assists |\n",
    "| **Alpha per 90** | Finishing Alpha / 90s | Rate-adjusted finishing outperformance |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Live example\n",
    "print(\"Finishing Alpha = Goals - xG\")\n",
    "print(\"Playmaking Alpha = Assists - xAG\")\n",
    "print()\n",
    "\n",
    "# Pick a well-known striker\n",
    "for name in ['Haaland', 'Mbapp\u00e9', 'Lewandowski', 'Salah']:\n",
    "    match = df[df['player'].str.contains(name, case=False, na=False)]\n",
    "    if len(match) > 0:\n",
    "        p = match.iloc[0]\n",
    "        print(f\"{p['player']} ({p['squad']})\")\n",
    "        print(f\"  Goals: {p['gls']:.0f}, xG: {p['xg']:.1f} \u2192 Finishing Alpha: {p['finishing_alpha']:+.2f}\")\n",
    "        if pd.notna(p.get('xag')):\n",
    "            print(f\"  Assists: {p['ast']:.0f}, xAG: {p['xag']:.1f} \u2192 Playmaking Alpha: {p['playmaking_alpha']:+.2f}\")\n",
    "        print()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Finishing Alpha Distribution"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "fa = df['finishing_alpha'].dropna()\n",
    "axes[0].hist(fa, bins=50, edgecolor='black', color='#3498db')\n",
    "axes[0].axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero (Expected)')\n",
    "axes[0].axvline(x=fa.mean(), color='green', linestyle='--', linewidth=2, label=f\"Mean: {fa.mean():.2f}\")\n",
    "axes[0].set_xlabel('Finishing Alpha')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Finishing Alpha Distribution')\n",
    "axes[0].legend()\n",
    "\n",
    "df.boxplot(column='finishing_alpha', by='main_pos', ax=axes[1])\n",
    "axes[1].axhline(y=0, color='red', linestyle='--')\n",
    "axes[1].set_title('Finishing Alpha by Position')\n",
    "axes[1].set_xlabel('Position')\n",
    "plt.suptitle('')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. xG vs Actual Goals Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "mask = df['xg'].notna() & df['gls'].notna()\n",
    "plot_df = df[mask]\n",
    "\n",
    "scatter = plt.scatter(plot_df['xg'], plot_df['gls'], alpha=0.5, \n",
    "                      c=plot_df['finishing_alpha'], cmap='RdYlGn', s=50)\n",
    "plt.colorbar(scatter, label='Finishing Alpha')\n",
    "\n",
    "max_val = max(plot_df['xg'].max(), plot_df['gls'].max())\n",
    "plt.plot([0, max_val], [0, max_val], 'k--', linewidth=2, label='Perfect Conversion (Goals = xG)')\n",
    "\n",
    "# Label outliers\n",
    "top = plot_df.nlargest(8, 'finishing_alpha')\n",
    "worst = plot_df.nsmallest(5, 'finishing_alpha')\n",
    "outliers = pd.concat([top, worst])\n",
    "\n",
    "texts = [plt.text(row['xg'], row['gls'], row['player'], fontsize=9, fontweight='bold')\n",
    "         for _, row in outliers.iterrows()]\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='-', color='gray', lw=0.5))\n",
    "\n",
    "plt.xlabel('Expected Goals (xG)', fontsize=12)\n",
    "plt.ylabel('Actual Goals', fontsize=12)\n",
    "plt.title('xG vs Actual Goals - Who Overperforms?', fontsize=14)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Top Clinical Finishers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "top_finishers = df.dropna(subset=['finishing_alpha']).nlargest(15, 'finishing_alpha')\n",
    "top_finishers[['player', 'squad', 'comp', 'gls', 'xg', 'finishing_alpha']].reset_index(drop=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "top15 = df.dropna(subset=['finishing_alpha']).nlargest(15, 'finishing_alpha')\n",
    "plt.barh(top15['player'], top15['finishing_alpha'], color='#2ecc71')\n",
    "plt.xlabel('Finishing Alpha (Goals \u2212 xG)')\n",
    "plt.title('Top 15 Clinical Finishers - Overperforming xG')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Worst Finishers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "worst15 = df.dropna(subset=['finishing_alpha']).nsmallest(15, 'finishing_alpha')\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(worst15['player'], worst15['finishing_alpha'], color='#e74c3c')\n",
    "plt.xlabel('Finishing Alpha (Goals \u2212 xG)')\n",
    "plt.title('Top 15 Underperforming Finishers - Below xG')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Playmaking Alpha Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "mask = df['xag'].notna() & df['ast'].notna()\n",
    "plot_df = df[mask]\n",
    "\n",
    "scatter = plt.scatter(plot_df['xag'], plot_df['ast'], alpha=0.5,\n",
    "                      c=plot_df['playmaking_alpha'], cmap='RdYlGn', s=50)\n",
    "plt.colorbar(scatter, label='Playmaking Alpha')\n",
    "\n",
    "max_val = max(plot_df['xag'].max(), plot_df['ast'].max())\n",
    "plt.plot([0, max_val], [0, max_val], 'k--', linewidth=2, label='Perfect Conversion')\n",
    "\n",
    "top_playmakers = plot_df.nlargest(10, 'playmaking_alpha')\n",
    "texts = [plt.text(row['xag'], row['ast'], row['player'], fontsize=9, fontweight='bold')\n",
    "         for _, row in top_playmakers.iterrows()]\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='-', color='gray', lw=0.5))\n",
    "\n",
    "plt.xlabel('Expected Assists (xAG)', fontsize=12)\n",
    "plt.ylabel('Actual Assists', fontsize=12)\n",
    "plt.title('xAG vs Actual Assists - Who Creates Beyond Expectations?', fontsize=14)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. xGChain & xGBuildup - Understat Advanced Metrics\n",
    "\n",
    "**xGChain**: Total xG of every possession chain a player is involved in (goals + assists + buildup).\n",
    "**xGBuildup**: Same as xGChain but excluding the final shot and assist."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if 'xgchain' in df.columns and 'xgbuildup' in df.columns:\n",
    "    chain_df = df.dropna(subset=['xgchain', 'xgbuildup'])\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # xGChain vs Goals+Assists\n",
    "    chain_df['g_a'] = chain_df['gls'] + chain_df['ast']\n",
    "    axes[0].scatter(chain_df['xgchain'], chain_df['g_a'], alpha=0.4, s=30, color='#3498db')\n",
    "    axes[0].set_xlabel('xGChain')\n",
    "    axes[0].set_ylabel('Goals + Assists')\n",
    "    axes[0].set_title('xGChain vs Goal Contributions')\n",
    "    \n",
    "    # xGBuildup - pure buildup players\n",
    "    top_buildup = chain_df.nlargest(15, 'xgbuildup')\n",
    "    axes[1].barh(top_buildup['player'], top_buildup['xgbuildup'], color='#9b59b6')\n",
    "    axes[1].set_xlabel('xGBuildup')\n",
    "    axes[1].set_title('Top 15 Buildup Contributors')\n",
    "    axes[1].invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"xGChain/xGBuildup columns not available\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. League Comparison"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "league_alpha = df.groupby('comp').agg({\n",
    "    'finishing_alpha': 'mean',\n",
    "    'playmaking_alpha': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for i, (col, title) in enumerate([('finishing_alpha', 'Finishing'), ('playmaking_alpha', 'Playmaking')]):\n",
    "    order = league_alpha.sort_values(col).index\n",
    "    colors = ['#2ecc71' if league_alpha.loc[l, col] > 0 else '#e74c3c' for l in order]\n",
    "    axes[i].barh(order, league_alpha.loc[order, col], color=colors)\n",
    "    axes[i].axvline(x=0, color='black', linewidth=0.5)\n",
    "    axes[i].set_xlabel(f'Average {title} Alpha')\n",
    "    axes[i].set_title(f'League {title} Efficiency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Team Efficiency Rankings"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "team_alpha = df.groupby('squad').agg({\n",
    "    'finishing_alpha': 'mean',\n",
    "    'player': 'count'\n",
    "}).rename(columns={'player': 'num_players'})\n",
    "\n",
    "team_alpha = team_alpha[team_alpha['num_players'] >= 5]\n",
    "top_teams = team_alpha.nlargest(15, 'finishing_alpha')\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['#2ecc71' if x > 0 else '#e74c3c' for x in top_teams['finishing_alpha']]\n",
    "plt.barh(top_teams.index, top_teams['finishing_alpha'], color=colors)\n",
    "plt.xlabel('Average Finishing Alpha')\n",
    "plt.title('Top 15 Most Clinical Teams (min. 5 players)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Alpha per 90 - Rate-Adjusted Analysis\n",
    "\n",
    "Alpha per 90 normalizes for playing time, revealing who is most clinical *per match*."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if 'alpha_per90' in df.columns:\n",
    "    qualified = df[(df['col_90s'] >= 5) & df['alpha_per90'].notna()]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    top10 = qualified.nlargest(10, 'alpha_per90')\n",
    "    axes[0].barh(top10['player'], top10['alpha_per90'], color='#2ecc71')\n",
    "    axes[0].set_xlabel('Alpha per 90')\n",
    "    axes[0].set_title('Top 10 - Finishing Alpha per 90 (min 5 90s)')\n",
    "    axes[0].invert_yaxis()\n",
    "    \n",
    "    worst10 = qualified.nsmallest(10, 'alpha_per90')\n",
    "    axes[1].barh(worst10['player'], worst10['alpha_per90'], color='#e74c3c')\n",
    "    axes[1].set_xlabel('Alpha per 90')\n",
    "    axes[1].set_title('Worst 10 - Finishing Alpha per 90 (min 5 90s)')\n",
    "    axes[1].invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "1. **Distribution**: Most players cluster around zero alpha (the model is well-calibrated)\n",
    "2. **Outliers**: Elite finishers consistently overperform xG by 3-8 goals per season\n",
    "3. **Position Effect**: Forwards have highest variance; midfielders are closer to expectation\n",
    "4. **xGChain**: Shows total involvement in goal-scoring - not just the final action\n",
    "5. **xGBuildup**: Identifies \"invisible\" contributors who facilitate goals without scoring\n",
    "6. **League Differences**: Each league has distinct finishing/playmaking efficiency profiles\n",
    "7. **Alpha per 90**: Better metric for comparing players with different playing time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}